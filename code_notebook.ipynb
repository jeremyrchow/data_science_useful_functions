{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Recycled Code Notebook\n",
    "Bits of code taken from across the web or written by myself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" \n",
    "    Iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.   \n",
    "    libraries: \n",
    "        numpy as np \n",
    "        pandas as pd\n",
    "    Input: \n",
    "        df (pd.Dataframe):\n",
    "    Output:\n",
    "        df (pd.Dataframe):\n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is stolen from Chris Deotte. \n",
    "def relax_data(df_train, df_test, col):\n",
    "    '''\n",
    "    This is where I want to introduce a little trick to you, called data relaxation.\n",
    "    So what is it? In order to understand it take a look at the plot above. See the distibution\n",
    "    difference between train and test set at a certain point? Gradient boosting algorithm \n",
    "    doesn't know what to do with a data it has never seen so it will not approximate it well.\n",
    "    And what we do by relaxing data is we are removing all the values from the train set\n",
    "    that appears in it 3 times more often than in a test set and vice versa, also \n",
    "    cleaning all the data that appears in train and test set only couple of times.\n",
    "    libraries: pandas as pd\n",
    "    inputs:\n",
    "        df_train (pd.DataFrame):\n",
    "        df_test (pd.DataFrame):\n",
    "        col: string, column name of desired data to relax\n",
    "    '''\n",
    "    cv1 = pd.DataFrame(df_train[col].value_counts().reset_index().rename({col:'train'},axis=1))\n",
    "    cv2 = pd.DataFrame(df_test[col].value_counts().reset_index().rename({col:'test'},axis=1))\n",
    "    cv3 = pd.merge(cv1,cv2,on='index',how='outer')\n",
    "    factor = len(df_test)/len(df_train)\n",
    "    cv3['train'].fillna(0,inplace=True)\n",
    "    cv3['test'].fillna(0,inplace=True)\n",
    "    cv3['remove'] = False\n",
    "    cv3['remove'] = cv3['remove'] | (cv3['train'] < len(df_train)/10000)\n",
    "    cv3['remove'] = cv3['remove'] | (factor*cv3['train'] < cv3['test']/3)\n",
    "    cv3['remove'] = cv3['remove'] | (factor*cv3['train'] > 3*cv3['test'])\n",
    "    cv3['new'] = cv3.apply(lambda x: x['index'] if x['remove']==False else 0,axis=1)\n",
    "    cv3['new'],_ = cv3['new'].factorize(sort=True)\n",
    "    cv3.set_index('index',inplace=True)\n",
    "    cc = cv3['new'].to_dict()\n",
    "    df_train[col] = df_train[col].map(cc)\n",
    "    df_test[col] = df_test[col].map(cc)\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_numerical(train,test,feature):\n",
    "    \"\"\"\n",
    "    Plot some information about a numerical feature for both train and test set.\n",
    "    Libraries:\n",
    "        pandas as pd\n",
    "        matplotlib.pyplot as plt\n",
    "        seaborn as sns\n",
    "    Args:\n",
    "        train (pd.DataFrame):\n",
    "        test (pd.DataFrame):\n",
    "        feature (str): name of the column in DataFrame\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(16, 18))\n",
    "    sns.kdeplot(train[feature], ax=axes[0][0], label='Train');\n",
    "    sns.kdeplot(test[feature], ax=axes[0][0], label='Test');\n",
    "\n",
    "    sns.kdeplot(train[train['isFraud']==0][feature], ax=axes[0][1], label='isFraud 0')\n",
    "    sns.kdeplot(train[train['isFraud']==1][feature], ax=axes[0][1], label='isFraud 1')\n",
    "\n",
    "    test[feature].index += len(train)\n",
    "    axes[1][0].plot(train[feature], '.', label='Train');\n",
    "    axes[1][0].plot(test[feature], '.', label='Test');\n",
    "    axes[1][0].set_xlabel('row index');\n",
    "    axes[1][0].legend()\n",
    "    test[feature].index -= len(train)\n",
    "\n",
    "    axes[1][1].plot(train[train['isFraud']==0][feature], '.', label='isFraud 0');\n",
    "    axes[1][1].plot(train[train['isFraud']==1][feature], '.', label='isFraud 1');\n",
    "    axes[1][1].set_xlabel('row index');\n",
    "    axes[1][1].legend()\n",
    "\n",
    "    pd.DataFrame({'train': [train[feature].isnull().sum()],\n",
    "                  'test': [test[feature].isnull().sum()]}).plot(kind='bar', rot=0, ax=axes[2][0]);\n",
    "    pd.DataFrame({'isFraud 0': [train[(train['isFraud']==0) &\n",
    "                                      (train[feature].isnull())][feature].shape[0]],\n",
    "                  'isFraud 1': [train[(train['isFraud']==1) &\n",
    "                                      (train[feature].isnull())][feature].shape[0]]}).plot(kind='bar',\n",
    "                                                                                           rot=0,\n",
    "                                                                                           ax=axes[2][1]);\n",
    "\n",
    "    fig.suptitle(feature, fontsize=18);\n",
    "    axes[0][0].set_title('Train/Test KDE distribution');\n",
    "    axes[0][1].set_title('Target value KDE distribution');\n",
    "    axes[1][0].set_title('Index versus value: Train/Test distribution');\n",
    "    axes[1][1].set_title('Index versus value: Target distribution');\n",
    "    axes[2][0].set_title('Number of NaNs');\n",
    "    axes[2][1].set_title('Target value distribution among NaN values');\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def plot_categorical(train: pd.DataFrame, test: pd.DataFrame, feature: str, target: str, values: int=5):\n",
    "    \"\"\"\n",
    "    Plotting distribution for the selected amount of most frequent values between train and test\n",
    "    along with distibution of target\n",
    "    Args:\n",
    "        train (pandas.DataFrame): training set\n",
    "        test (pandas.DataFrame): testing set\n",
    "        feature (str): name of the feature\n",
    "        target (str): name of the target feature\n",
    "        values (int): amount of most frequest values to look at\n",
    "    \"\"\"\n",
    "    df_train = pd.DataFrame(data={feature: train[feature], 'isTest': 0})\n",
    "    df_test = pd.DataFrame(data={feature: test[feature], 'isTest': 1})\n",
    "    df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "    df = df[df[feature].isin(df[feature].value_counts(dropna=False).head(values).index)]\n",
    "    train = train[train[feature].isin(train[feature].value_counts(dropna=False).head(values).index)]\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 12))\n",
    "    sns.countplot(data=df.fillna('NaN'), x=feature, hue='isTest', ax=axes[0]);\n",
    "    sns.countplot(data=train[[feature, target]].fillna('NaN'), x=feature, hue=target, ax=axes[1]);\n",
    "    axes[0].set_title('Train / Test distibution of {} most frequent values'.format(values));\n",
    "    axes[1].set_title('Train distibution by {} of {} most frequent values'.format(target, values));\n",
    "    axes[0].legend(['Train', 'Test']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
